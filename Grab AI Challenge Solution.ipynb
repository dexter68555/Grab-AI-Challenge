{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Making a car classifier using Pytorch\n\nIn this notebook I'm making a car classifier using the Stanford car dataset, which contains 196 classes.\nI'll be using a pre-trained resnet34 with transfer learning to train the model. All layers will be fine tuned and the last fully connected layer will be replaced entirely.\n\nDataset (196 classes):\n\nTrain folder: 8144 images, avg: 41.5 images per class.\n\nTest folder: 8041 images, avg: 41.0 images per class."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.models as models\nimport torchvision.transforms as transforms\n\ntorch.manual_seed(0)\n\nfrom torch.utils.data import Dataset\n\nfrom torch.utils import data as D\n\nimport time\nimport os\nimport PIL.Image as Image\nfrom IPython.display import display\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nprint(torch.cuda.get_device_name(device))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the data and transform\n\nFirst, lets create some transforms for our data and load the train/test data+labels from the folders.\n\nHere we are using 300x300 images with random horizontal flip, random rotation and normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_dir = \"../input/car_data/car_data/\"\n\ntrain_tfms = transforms.Compose([transforms.Resize((400, 400)),\n                                 transforms.RandomHorizontalFlip(),\n                                 transforms.RandomRotation(15),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntest_tfms = transforms.Compose([transforms.Resize((400, 400)),\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ndataset = torchvision.datasets.ImageFolder(root=dataset_dir+\"train\", transform = train_tfms)\n\n\n#testloader = train_valid_split(trainloader)\n\ntrain_len = int(0.9 * 8144)\nvalid_len = 8144 - train_len\ndataset, dataset3 = D.random_split(dataset, lengths=[train_len, valid_len])\n\ntrainloader = torch.utils.data.DataLoader(dataset, batch_size = 32, shuffle=True, num_workers = 2)\n\ntestloader = torch.utils.data.DataLoader(dataset3, batch_size = 32, shuffle=True, num_workers = 2)\n\ndataset2 = torchvision.datasets.ImageFolder(root=dataset_dir+\"test\", transform = test_tfms)\ntestloader2 = torch.utils.data.DataLoader(dataset2, batch_size = 32, shuffle=False, num_workers = 2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model training function\n\nHere we train our model, after each epoch, we test the model on the test data to see how it's going"},{"metadata":{"trusted":false},"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, n_epochs = 5):\n    \n    losses = []\n    accuracies = []\n    test_accuracies = []\n    # set the model to train mode initially\n    model.train()\n    for epoch in range(n_epochs):\n        since = time.time()\n        running_loss = 0.0\n        running_correct = 0.0\n        for i, data in enumerate(trainloader, 0):\n\n            # get the inputs and assign them to cuda\n            inputs, labels = data\n            #inputs = inputs.to(device).half() # uncomment for half precision model\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            \n            # forward + backward + optimize\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            # calculate the loss/acc later\n            running_loss += loss.item()\n            running_correct += (labels==predicted).sum().item()\n\n        epoch_duration = time.time()-since\n        epoch_loss = running_loss/len(trainloader)\n        epoch_acc = 100/32*running_correct/len(trainloader)\n        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n        \n        losses.append(epoch_loss)\n        accuracies.append(epoch_acc)\n        \n        # switch the model to eval mode to evaluate on test data\n        model.eval()\n        test_acc = eval_model(model)\n        test_accuracies.append(test_acc)\n        test_acc2 = eval_model3(model)\n        \n        \n        # re-set the model to train mode after validating\n        model.train()\n        scheduler.step(test_acc)\n        #scheduler.step(epoch_acc)\n        since = time.time()\n        \n    model.eval()\n    testing_accuracy = eval_model2(model)\n    print('Finished Training')\n    model.train()\n    return model, losses, accuracies, test_accuracies\n\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluate on training data\nThis function is called out after each epoch of training on the training data. We then measure the accuracy of the model."},{"metadata":{"trusted":false},"cell_type":"code","source":"\ndef eval_model3(model):\n    correct = 0.0\n    total = 0.0\n    \n    with torch.no_grad():\n        for i, data in enumerate(testloader2, 0):\n            images, labels = data\n            #images = images.to(device).half() # uncomment for half precision model\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model_ft(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    test_acc = 100.0 * correct / total\n    print('Accuracy of the network on the test images: %.2f %%' % (\n        test_acc))\n    return test_acc\n\ndef eval_model(model):\n    correct = 0.0\n    total = 0.0\n    \n    with torch.no_grad():\n        for i, data in enumerate(testloader, 0):\n            images, labels = data\n            #images = images.to(device).half() # uncomment for half precision model\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model_ft(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    test_acc = 100.0 * correct / total\n    print('Accuracy of the network on the validation images: %.2f %%' % (\n        test_acc))\n    return test_acc\n\nresult = []\nactual = []\nresult2 = []\n\ndef eval_model2(model):\n    correct = 0.0\n    total = 0.0\n    \n    with torch.no_grad():\n        for i, data in enumerate(testloader2, 0):\n            images, labels = data\n            #images = images.to(device).half() # uncomment for half precision model\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model_ft(images)\n            _, predicted = torch.max(outputs.data, 1)\n            result.append(predicted.cpu().numpy())\n            \n            tmp_predict = outputs.data\n            predicted2 = torch.nn.functional.softmax(tmp_predict)\n            result2.append(predicted2.data.cpu().numpy())\n            actual.append(labels.cpu().numpy())\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    test_acc = 100.0 * correct / total\n    print('Accuracy of the network on the test images: %.2f %%' % (\n        test_acc))\n    return test_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_ft = models.resnet101(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n\n# replace the last fc layer with an untrained one (requires grad by default)\nmodel_ft.fc = nn.Linear(num_ftrs, 196)\nmodel_ft = model_ft.to(device)\n\n# uncomment this block for half precision model\n\"\"\"\nmodel_ft = model_ft.half()\n\n\nfor layer in model_ft.modules():\n    if isinstance(layer, nn.BatchNorm2d):\n        layer.float()\n\"\"\"\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n\n\"\"\"\nprobably not the best metric to track, but we are tracking the training accuracy and measuring whether\nit increases by atleast 0.9 per epoch and if it hasn't increased by 0.9 reduce the lr by 0.1x.\nHowever in this model it did not benefit me.\n\"\"\"\nlrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_ft, training_losses, training_accs, test_accs = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final = []\nfor sublist in result:\n    for item in sublist:\n        final.append(item)\n\nsubmission = pd.DataFrame.from_dict({\n    'prediction': final\n})\n\nsubmission.to_csv('result.csv', index=False)\n        \nreal = []\nfor sublist in actual:\n    for item in sublist:\n        real.append(item)\n\n\n\nsubmission2 = pd.DataFrame.from_dict({\n    'actual': real\n})\n\nsubmission2.to_csv('actual.csv', index=False)\n\nfinal2 = []\nfor sublist in result2:\n    for item in sublist:\n        final2.append(item)\n\nsubmission = pd.DataFrame.from_dict({\n    'prediction': final2\n})\n\nsubmission.to_csv('confidence.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":1}