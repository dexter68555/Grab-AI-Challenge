{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a car classifier using Pytorch\n",
    "\n",
    "In this notebook I'm making a car classifier using the Stanford car dataset, which contains 196 classes.\n",
    "I'll be using a pre-trained resnet34 with transfer learning to train the model. All layers will be fine tuned and the last fully connected layer will be replaced entirely.\n",
    "\n",
    "Dataset (196 classes):\n",
    "\n",
    "Train folder: 8144 images, avg: 41.5 images per class.\n",
    "\n",
    "Test folder: 8041 images, avg: 41.0 images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torch.utils import data as D\n",
    "\n",
    "import time\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "from IPython.display import display\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and transform\n",
    "\n",
    "First, lets create some transforms for our data and load the train/test data+labels from the folders.\n",
    "\n",
    "Here we are using 300x300 images with random horizontal flip, random rotation and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../input/car_data/car_data/\"\n",
    "\n",
    "train_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomRotation(15),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "test_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(root=dataset_dir+\"train\", transform = train_tfms)\n",
    "\n",
    "\n",
    "#testloader = train_valid_split(trainloader)\n",
    "\n",
    "train_len = int(0.9 * 8144)\n",
    "valid_len = 8144 - train_len\n",
    "dataset, dataset3 = D.random_split(dataset, lengths=[train_len, valid_len])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size = 32, shuffle=True, num_workers = 2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(dataset3, batch_size = 32, shuffle=True, num_workers = 2)\n",
    "\n",
    "dataset2 = torchvision.datasets.ImageFolder(root=dataset_dir+\"test\", transform = test_tfms)\n",
    "testloader2 = torch.utils.data.DataLoader(dataset2, batch_size = 32, shuffle=False, num_workers = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training function\n",
    "\n",
    "Here we train our model, after each epoch, we test the model on the test data to see how it's going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, n_epochs = 5):\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    test_accuracies = []\n",
    "    # set the model to train mode initially\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            # get the inputs and assign them to cuda\n",
    "            inputs, labels = data\n",
    "            #inputs = inputs.to(device).half() # uncomment for half precision model\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # calculate the loss/acc later\n",
    "            running_loss += loss.item()\n",
    "            running_correct += (labels==predicted).sum().item()\n",
    "\n",
    "        epoch_duration = time.time()-since\n",
    "        epoch_loss = running_loss/len(trainloader)\n",
    "        epoch_acc = 100/32*running_correct/len(trainloader)\n",
    "        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n",
    "        \n",
    "        losses.append(epoch_loss)\n",
    "        accuracies.append(epoch_acc)\n",
    "        \n",
    "        # switch the model to eval mode to evaluate on test data\n",
    "        model.eval()\n",
    "        test_acc = eval_model(model)\n",
    "        test_accuracies.append(test_acc)\n",
    "        test_acc2 = eval_model3(model)\n",
    "        \n",
    "        \n",
    "        # re-set the model to train mode after validating\n",
    "        model.train()\n",
    "        scheduler.step(test_acc)\n",
    "        #scheduler.step(epoch_acc)\n",
    "        since = time.time()\n",
    "        \n",
    "    model.eval()\n",
    "    testing_accuracy = eval_model2(model)\n",
    "    print('Finished Training')\n",
    "    model.train()\n",
    "    return model, losses, accuracies, test_accuracies\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on training data\n",
    "This function is called out after each epoch of training on the training data. We then measure the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_model3(model):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader2, 0):\n",
    "            images, labels = data\n",
    "            #images = images.to(device).half() # uncomment for half precision model\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_ft(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = 100.0 * correct / total\n",
    "    print('Accuracy of the network on the test images: %.2f %%' % (\n",
    "        test_acc))\n",
    "    return test_acc\n",
    "\n",
    "def eval_model(model):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            images, labels = data\n",
    "            #images = images.to(device).half() # uncomment for half precision model\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_ft(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = 100.0 * correct / total\n",
    "    print('Accuracy of the network on the validation images: %.2f %%' % (\n",
    "        test_acc))\n",
    "    return test_acc\n",
    "\n",
    "result = []\n",
    "actual = []\n",
    "result2 = []\n",
    "\n",
    "def eval_model2(model):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader2, 0):\n",
    "            images, labels = data\n",
    "            #images = images.to(device).half() # uncomment for half precision model\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_ft(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            result.append(predicted.cpu().numpy())\n",
    "            \n",
    "            tmp_predict = outputs.data\n",
    "            predicted2 = torch.nn.functional.softmax(tmp_predict)\n",
    "            result2.append(predicted2.data.cpu().numpy())\n",
    "            actual.append(labels.cpu().numpy())\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = 100.0 * correct / total\n",
    "    print('Accuracy of the network on the test images: %.2f %%' % (\n",
    "        test_acc))\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /tmp/.torch/models/resnet101-5d3b4d8f.pth\n",
      "178728960it [00:23, 7663743.64it/s]\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet101(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# replace the last fc layer with an untrained one (requires grad by default)\n",
    "model_ft.fc = nn.Linear(num_ftrs, 196)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# uncomment this block for half precision model\n",
    "\"\"\"\n",
    "model_ft = model_ft.half()\n",
    "\n",
    "\n",
    "for layer in model_ft.modules():\n",
    "    if isinstance(layer, nn.BatchNorm2d):\n",
    "        layer.float()\n",
    "\"\"\"\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "\"\"\"\n",
    "probably not the best metric to track, but we are tracking the training accuracy and measuring whether\n",
    "it increases by atleast 0.9 per epoch and if it hasn't increased by 0.9 reduce the lr by 0.1x.\n",
    "However in this model it did not benefit me.\n",
    "\"\"\"\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, duration: 211 s, loss: 4.2873, acc: 10.6114\n",
      "Accuracy of the network on the validation images: 15.71 %\n",
      "Accuracy of the network on the test images: 16.76 %\n",
      "Epoch 2, duration: 209 s, loss: 2.1151, acc: 44.8234\n",
      "Accuracy of the network on the validation images: 42.70 %\n",
      "Accuracy of the network on the test images: 45.09 %\n",
      "Epoch 3, duration: 210 s, loss: 1.1412, acc: 68.9946\n",
      "Accuracy of the network on the validation images: 59.63 %\n",
      "Accuracy of the network on the test images: 61.26 %\n",
      "Epoch 4, duration: 209 s, loss: 0.7624, acc: 79.7147\n",
      "Accuracy of the network on the validation images: 68.22 %\n",
      "Accuracy of the network on the test images: 69.99 %\n",
      "Epoch 5, duration: 209 s, loss: 0.5323, acc: 85.2310\n",
      "Accuracy of the network on the validation images: 68.59 %\n",
      "Accuracy of the network on the test images: 68.75 %\n",
      "Epoch 6, duration: 209 s, loss: 0.3970, acc: 89.5245\n",
      "Accuracy of the network on the validation images: 68.47 %\n",
      "Accuracy of the network on the test images: 72.33 %\n",
      "Epoch 7, duration: 209 s, loss: 0.1688, acc: 96.3723\n",
      "Accuracy of the network on the validation images: 90.31 %\n",
      "Accuracy of the network on the test images: 90.21 %\n",
      "Epoch 8, duration: 210 s, loss: 0.1185, acc: 97.5272\n",
      "Accuracy of the network on the validation images: 90.31 %\n",
      "Accuracy of the network on the test images: 91.00 %\n",
      "Epoch 9, duration: 209 s, loss: 0.1097, acc: 97.9212\n",
      "Accuracy of the network on the validation images: 91.17 %\n",
      "Accuracy of the network on the test images: 90.75 %\n",
      "Epoch 10, duration: 209 s, loss: 0.0941, acc: 98.1522\n",
      "Accuracy of the network on the validation images: 91.04 %\n",
      "Accuracy of the network on the test images: 91.27 %\n",
      "Epoch 11, duration: 209 s, loss: 0.0873, acc: 98.4783\n",
      "Accuracy of the network on the validation images: 91.17 %\n",
      "Accuracy of the network on the test images: 90.90 %\n",
      "Epoch 12, duration: 209 s, loss: 0.0806, acc: 98.4918\n",
      "Accuracy of the network on the validation images: 91.66 %\n",
      "Accuracy of the network on the test images: 91.29 %\n",
      "Epoch 13, duration: 209 s, loss: 0.0782, acc: 98.7364\n",
      "Accuracy of the network on the validation images: 91.04 %\n",
      "Accuracy of the network on the test images: 91.43 %\n",
      "Epoch 14, duration: 210 s, loss: 0.0745, acc: 98.7500\n",
      "Accuracy of the network on the validation images: 91.66 %\n",
      "Accuracy of the network on the test images: 91.56 %\n",
      "Epoch 15, duration: 209 s, loss: 0.0835, acc: 98.7636\n",
      "Accuracy of the network on the validation images: 90.67 %\n",
      "Accuracy of the network on the test images: 91.82 %\n",
      "Epoch 16, duration: 209 s, loss: 0.0818, acc: 98.6549\n",
      "Accuracy of the network on the validation images: 92.02 %\n",
      "Accuracy of the network on the test images: 91.43 %\n",
      "Epoch 17, duration: 210 s, loss: 0.0777, acc: 98.6821\n",
      "Accuracy of the network on the validation images: 91.17 %\n",
      "Accuracy of the network on the test images: 91.46 %\n",
      "Epoch 18, duration: 209 s, loss: 0.0772, acc: 98.6821\n",
      "Accuracy of the network on the validation images: 91.78 %\n",
      "Accuracy of the network on the test images: 91.31 %\n",
      "Epoch 19, duration: 209 s, loss: 0.0778, acc: 98.7636\n",
      "Accuracy of the network on the validation images: 91.66 %\n",
      "Accuracy of the network on the test images: 91.18 %\n",
      "Epoch 20, duration: 209 s, loss: 0.0769, acc: 98.8043\n",
      "Accuracy of the network on the validation images: 91.78 %\n",
      "Accuracy of the network on the test images: 91.39 %\n",
      "Epoch 21, duration: 210 s, loss: 0.0844, acc: 98.7364\n",
      "Accuracy of the network on the validation images: 91.66 %\n",
      "Accuracy of the network on the test images: 91.23 %\n",
      "Epoch 22, duration: 209 s, loss: 0.0795, acc: 98.7228\n",
      "Accuracy of the network on the validation images: 91.29 %\n",
      "Accuracy of the network on the test images: 91.57 %\n",
      "Epoch 23, duration: 209 s, loss: 0.0792, acc: 98.7092\n",
      "Accuracy of the network on the validation images: 91.53 %\n",
      "Accuracy of the network on the test images: 91.24 %\n",
      "Epoch 24, duration: 210 s, loss: 0.0746, acc: 98.7636\n",
      "Accuracy of the network on the validation images: 91.41 %\n",
      "Accuracy of the network on the test images: 91.17 %\n",
      "Epoch 25, duration: 209 s, loss: 0.0851, acc: 98.7500\n",
      "Accuracy of the network on the validation images: 91.78 %\n",
      "Accuracy of the network on the test images: 91.11 %\n",
      "Epoch 26, duration: 209 s, loss: 0.0771, acc: 98.7908\n",
      "Accuracy of the network on the validation images: 91.66 %\n",
      "Accuracy of the network on the test images: 91.52 %\n",
      "Epoch 27, duration: 209 s, loss: 0.0743, acc: 98.7500\n",
      "Accuracy of the network on the validation images: 92.39 %\n",
      "Accuracy of the network on the test images: 91.53 %\n",
      "Epoch 28, duration: 209 s, loss: 0.0770, acc: 98.7092\n",
      "Accuracy of the network on the validation images: 92.15 %\n",
      "Accuracy of the network on the test images: 91.21 %\n",
      "Epoch 29, duration: 210 s, loss: 0.0725, acc: 98.8179\n",
      "Accuracy of the network on the validation images: 91.53 %\n",
      "Accuracy of the network on the test images: 91.17 %\n",
      "Epoch 30, duration: 210 s, loss: 0.0753, acc: 98.8587\n",
      "Accuracy of the network on the validation images: 91.41 %\n",
      "Accuracy of the network on the test images: 91.18 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 91.18 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model_ft, training_losses, training_accs, test_accs = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for sublist in result:\n",
    "    for item in sublist:\n",
    "        final.append(item)\n",
    "\n",
    "submission = pd.DataFrame.from_dict({\n",
    "    'prediction': final\n",
    "})\n",
    "\n",
    "submission.to_csv('result.csv', index=False)\n",
    "        \n",
    "real = []\n",
    "for sublist in actual:\n",
    "    for item in sublist:\n",
    "        real.append(item)\n",
    "\n",
    "\n",
    "\n",
    "submission2 = pd.DataFrame.from_dict({\n",
    "    'actual': real\n",
    "})\n",
    "\n",
    "submission2.to_csv('actual.csv', index=False)\n",
    "\n",
    "final2 = []\n",
    "for sublist in result2:\n",
    "    for item in sublist:\n",
    "        final2.append(item)\n",
    "\n",
    "submission = pd.DataFrame.from_dict({\n",
    "    'prediction': final2\n",
    "})\n",
    "\n",
    "submission.to_csv('confidence.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
